Here are detailed notes from the video "Hadoop Tutorial - Architecture" to help you study for your interview and exam:

### HDFS Architecture and Core Concepts

*   **HDFS (Hadoop Distributed File System)** is a **distributed file system**.
*   It is designed using a **master/slave architecture**.

#### Hadoop Cluster Setup

*   A Hadoop cluster consists of **multiple computers networked together**.
*   **Racks**:
    *   A rack is a physical enclosure where multiple computers are fixed.
    *   Each rack typically has its **individual power supply** and a **dedicated network switch**.
    *   The importance of racks lies in the **possibility of an entire rack failing** if its switch or power supply goes out of network, affecting all computers within it.
    *   Multiple racks are connected, with their switches linked to a core switch, forming the Hadoop cluster.

#### Master/Slave Architecture: NameNode and DataNode

In HDFS, there is **one master** and **multiple slaves**.

1.  **NameNode (Master Node)**:
    *   The Hadoop master is called the **NameNode**.
    *   It is called NameNode because it **stores and manages the names of directories and files** within the HDFS namespace.
    *   **Responsibilities**:
        *   Manages the **file system namespace**.
        *   Regulates **access to files by clients** (e.g., checking access permissions, user quotas).
        *   Maintains an **image of the entire HDFS namespace in memory**, known as **in-memory FS image (File System Image)**. This allows it to perform checks quickly.
        *   **Does not store actual file data**.
        *   **Assigns DataNodes for block storage** based on free disk space information from DataNodes.
        *   Maintains the **mapping of blocks to files**, their order, and all other metadata.

2.  **DataNode (Slave Node)**:
    *   The Hadoop slaves are called **DataNodes**.
    *   They are called DataNodes because they **store and manage the actual data of the files**.
    *   **Responsibilities**:
        *   **Stores file data in the form of blocks**.
        *   Periodically sends a **heartbeat** to the NameNode to signal that it is alive. This heartbeat also includes **resource capacity information** that helps the NameNode in making decisions.
        *   Sends a **block report** to the NameNode, which is health information about all the blocks maintained by that DataNode.

#### File Creation and Writing Process in HDFS

This process involves three main actors: the **Hadoop Client**, the **Hadoop NameNode**, and the **Hadoop DataNode**.

1.  **Client Request**: The Hadoop client sends a request to the NameNode to create a file, providing the target directory name and the file name.
2.  **NameNode Checks**: On receiving the request, the NameNode performs various checks, such as:
    *   If the directory already exists.
    *   If the file doesn't already exist.
    *   If the client has the necessary permissions to create the file.
    *   These checks are possible because the NameNode maintains the **in-memory FS image**.
3.  **File Entry Creation**: If all checks pass, the NameNode creates an entry for the new file and returns success to the client. At this point, the file is empty.
4.  **Writing Data**:
    *   The client creates an **FSDataOutputStream** (a Hadoop streamer) and begins writing data to this stream.
    *   The FSDataOutputStream **buffers the data locally** until a reasonable amount, typically **128 MB**, accumulates. This accumulated data is called a **block** (or HDFS data block).
    *   Once a block of data is ready, the streamer contacts the **NameNode, asking for block allocation** (i.e., where to store this block).
    *   The NameNode, knowing the amount of free disk space at each DataNode, **assigns a DataNode** (or multiple for replication, though not detailed here) to store that block. It then sends the DataNode's name back to the streamer.
    *   The streamer then **directly sends the block to the assigned DataNode**.
    *   If the file is larger than one block, the streamer repeats the process, requesting a new block allocation from the NameNode. The NameNode may assign a different DataNode for the next block, meaning different blocks of the same file can reside on different DataNodes.
5.  **Commit Changes**: Once the client finishes writing to the file, the NameNode commits all the changes.

#### Key Takeaways and Core Architecture Elements

*   **HDFS has a master/slave architecture**.
*   An HDFS cluster typically consists of a **single NameNode and several DataNodes**.
*   The **NameNode manages the file system namespace** and regulates client access.
*   **DataNodes store file data in blocks**.
*   **Heartbeat and Block Report**: DataNodes periodically send heartbeats and block reports to the NameNode for health and resource information.
*   **File Splitting**: HDFS splits files into one or more blocks and stores these blocks on different DataNodes.
*   **Metadata Management**: The NameNode maintains the mapping of blocks to files, their order, and other essential metadata.
*   **Block Size**:
    *   A typical block size in HDFS is **128 MB**.
    *   Block size can be specified on a per-file basis.
    *   This block size is **significantly larger than in local file systems**, which was a crucial design decision to **avoid disk seek overhead**.
    *   Some setups might even configure block sizes up to **256 MB**. However, a very large block size can have adverse impacts.
*   **Client-DataNode Interaction**: While the NameNode determines block-to-DataNode mapping, **after mapping, the client directly interacts with the DataNode for reading and writing data**.
*   **Client-Side Buffering**: When writing data, it first goes to a local buffer on the client side. This approach is adopted to provide **streaming read/write capability** to HDFS.
*   **Deployment**:
    *   NameNode and DataNode are software components.
    *   In a minimum configuration, both can run on the same machine to create a **single-node Hadoop cluster**.
    *   However, a typical deployment involves a **dedicated computer running only the NameNode software**, with each other machine in the cluster running one instance of the DataNode software.


Here are detailed notes from the video "Hadoop Tutorial - High Availability, Fault Tolerance & Secondary Name Node" to help you study for your interview and exam:

### Hadoop Fault Tolerance and High Availability

The video explains two critical features of Hadoop: **Fault Tolerance** and **High Availability**. While often confused, they serve different purposes.

#### 1. Fault Tolerance

Fault tolerance refers to the system's ability to continue operating despite failures. In Hadoop, this primarily addresses DataNode failures and data loss.

*   **Problem Statement**: If a DataNode fails, parts of your data file (blocks) stored on that node would be lost, making the file unreadable.
*   **Solution: Replication (Backup Copies of Blocks)**
    *   Hadoop offers a simple solution: create backup copies of each data block and store them on different DataNodes.
    *   If one copy becomes unavailable, the data can be read from another copy.
    *   This is called **replication** in Hadoop terminology.
    *   **Replication Factor**:
        *   You can set the replication factor on a file-by-file basis.
        *   It can even be changed *after* a file is created in HDFS.
        *   If a file's replication factor is set to two, HDFS automatically creates two copies of each block for that file.
        *   Hadoop ensures these copies are placed on **different machines**.
        *   Typically, the replication factor is set to **three**, which is considered reasonably good.
        *   For super-critical files, you can increase the replication factor to a higher value.
    *   **Rack Awareness**:
        *   A potential issue with replication is if an entire **rack fails** (e.g., due to a power outage or switch failure), all copies on that rack could be lost.
        *   Hadoop offers **rack awareness** to mitigate this.
        *   When configured for rack awareness, Hadoop ensures that at least **one copy of a block is placed in a different rack**. This protects against entire rack failures.
    *   **Maintaining Replication Factor**:
        *   The HDFS NameNode continuously tracks the replication factor of each block.
        *   If the number of replicas falls below the desired replication factor (e.g., due to a DataNode failure, a corrupted replica, or a hard disk failure on a DataNode), the NameNode will **initiate re-replication** to bring the block back to the desired number of replicas.
        *   This ensures continuous protection against failures.
    *   **Cost of Replication**:
        *   Creating multiple copies (e.g., three copies) significantly **reduces the effective storage capacity** of your cluster (e.g., to 1/3) and increases storage cost.
        *   However, traditional replication remains viable as disks are relatively cheap.
        *   **Alternatives**: Hadoop 2.x offers **storage policies** to minimize cost, and Hadoop 3.x provides **Erasure Coding** as an alternative to replication. These are more advanced topics not detailed in this video.

#### 2. High Availability (HA)

High availability refers to the **uptime of a system**, showing the percentage of time a service is operational. It's about ensuring the system remains available, even if individual components fail.

*   **Differentiating Fault Tolerance vs. High Availability**:
    *   Fault tolerance (like DataNode replication) prevents data loss and makes specific files available even if some DataNodes fail, but it **does not bring down the entire Hadoop system**.
    *   High availability, on the other hand, addresses scenarios where the *entire system* might become unusable.
*   **The NameNode as a Single Point of Failure (SPOF)**:
    *   The **NameNode is the only machine** in a Hadoop cluster that knows the file system namespace (list of directories and files) and manages file-to-block mapping.
    *   **Every client interaction starts with the NameNode**.
    *   If the NameNode fails, the entire Hadoop cluster becomes unusable; clients cannot read or write anything. Therefore, the NameNode is a **single point of failure**.
*   **Achieving NameNode High Availability**:
    *   To achieve HA for a Hadoop cluster, the NameNode must be protected against failures.
    *   The solution involves **creating a backup** of two crucial things:
        1.  **HDFS Namespace Information**: All information the NameNode maintains (in-memory FS image and edit log) must be continuously backed up.
        2.  **Standby NameNode Machine**: A pre-configured standby computer should be ready to take over the active NameNode's role rapidly.
*   **Namespace Information Backup (Edit Log Backup)**:
    *   The NameNode maintains the **in-memory FS image** (the complete picture of the file system) and an **edit log** on its local disk.
    *   Every change made to the file system is recorded in the edit log.
    *   The edit log is crucial because the in-memory FS image is lost on NameNode restart, but the FS image can be reconstructed from the edit log.
    *   **Quorum Journal Manager (QJM)**:
        *   Hadoop 2.x introduces QJM as the best solution for backing up the NameNode edit log.
        *   QJM consists of **at least three machines**, each running a **JournalNode daemon** (a lightweight software). These can be existing cluster machines.
        *   The NameNode is configured to write edit log entries to the QJM instead of its local disk.
        *   Having **three JournalNodes provides double protection** for the critical edit log. More nodes (e.g., five or seven) can be used for higher protection.
*   **Standby NameNode**:
    *   A new machine is added to the cluster and designated as the **Standby NameNode**.
    *   This Standby NameNode is configured to **continuously read the edit log from the QJM** and keep its own in-memory FS image updated.
    *   This ensures the Standby NameNode is always up-to-date and ready to take over the active role in seconds.
*   **DataNode Communication**:
    *   In an active-standby configuration, all **DataNodes are configured to send their block reports to *both* the active and standby NameNodes**. Block reports contain health information about the blocks on the DataNode.
*   **Failover Mechanism**:
    *   To determine when the Standby NameNode should take over, **ZooKeeper** and **Failover Controllers** are used.
    *   Each NameNode has a Failover Controller.
    *   The Failover Controller on the active NameNode maintains a **lock in ZooKeeper**.
    *   The Standby NameNode's Failover Controller continuously tries to acquire this lock.
    *   If the active NameNode fails or crashes, its lock in ZooKeeper expires.
    *   The Standby NameNode then successfully acquires the lock and transitions from standby to active role, knowing the active NameNode has failed.

#### 3. Secondary NameNode

The Secondary NameNode is a distinct component often confused with the Standby NameNode. Its purpose is **not** to provide high availability (i.e., not a backup for a failed NameNode).

*   **Primary Purpose: Minimizing NameNode Restart Time**
    *   When the NameNode restarts, it loses its in-memory FS image.
    *   It then reconstructs this image by reading the entire edit log.
    *   The problem is that the **edit log continuously grows**. If it becomes very large, NameNode restart times can become excessively long (e.g., an hour).
    *   The Secondary NameNode solves this by performing **checkpointing**.
*   **Checkpointing Process**:
    *   The Secondary NameNode performs a checkpoint activity typically **every hour**.
    *   During a checkpoint, it reads the current **edit log** and the existing **on-disk FS image** (the last saved state of the file system).
    *   It then **merges these changes** to create the latest file system state, which is equivalent to the in-memory FS image.
    *   This new, updated state is then **saved to disk as a new on-disk FS image**.
    *   After saving the new on-disk FS image, the Secondary NameNode instructs the active NameNode to **truncate (clear) the old edit log**, as all its changes have now been applied to the new FS image.
    *   This process ensures the edit log remains small, as it only contains changes accumulated since the last checkpoint.
    *   **FS Image vs. Edit Log Size**: The FS image is like a balance sheet (final state), while the edit log is a journal of every transaction. Therefore, the FS image is typically much smaller than a continuously growing edit log.
*   **Impact on NameNode Restart**: Because the edit log is kept short by checkpointing, when the NameNode restarts, it only needs to apply a small number of recent changes from the truncated edit log to the latest on-disk FS image, allowing it to restart very quickly.
*   **Redundancy in HA Setups**: When Hadoop High Availability (HA) configuration is implemented (with an Active and Standby NameNode), the **Standby NameNode also performs the checkpointing activity**. Therefore, a separate Secondary NameNode service is **not required** in an HA setup.





Here are detailed notes from the video "Hadoop Tutorials - Kerberos Authentication - Part 1" to help you study for your interview and exam:

This video focuses on **Kerberos authentication** and its implementation within a Hadoop cluster.

### 1. Understanding Authentication and Its Need in Hadoop

*   **Authentication** is the first level of security for any system. It involves validating the identity of a user or a process, essentially verifying "who you claim to be".
*   Beyond initial validation, the validated identity must **propagate** throughout the system with every action or resource access.
*   This kind of authentication is mandatory not only for users but also for **every process or service**.
*   **Without authentication**, a process or user could pose as a trusted identity to gain unauthorized access to data.
*   **Hadoop's Challenge**: Hadoop operates across a group of computers, each running an independent operating system (OS). While OS authentication works within the boundary of a single OS, Hadoop needs a **network-based authentication system** because it works across these boundaries.
*   Unfortunately, Hadoop **doesn't have a built-in capability** to authenticate users and propagate their identity.
*   The Hadoop community considered two options: develop an authentication capability into Hadoop or integrate with an existing network-based authentication system. They chose the latter.

### 2. Why Kerberos for Hadoop?

*   Hadoop uses **Kerberos for authentication and identity propagation**.
*   **Why Kerberos over others (e.g., SSL, OAuth)**:
    *   **OAuth was not available** at the time Hadoop's authentication solution was being decided.
    *   **Performance**: Kerberos performs better than SSL.
    *   **Simplicity**: Managing users in Kerberos is simpler than managing SSL certificates. For example, to remove a user, you simply delete them from Kerberos, whereas revoking an SSL certificate is a complicated process.

### 3. What is Kerberos?

*   Kerberos is a **network Authentication Protocol** created by MIT.
*   Its key feature is that it **eliminates the need for transmission of passwords across the network**, thereby removing the potential threat of an attacker "sniffing" the network. You do not send your password across the network after the initial authentication.

### 4. Kerberos Jargons and Components

To understand how Kerberos works, you need to know its core components:

*   **KDC (Key Distribution Center)**:
    *   The **authentication server** in a Kerberos environment.
    *   Most often resides on a separate physical server.
    *   Logically divided into three parts:
        *   **Database**: Stores user and service identities, known as **principles**. It also stores encryption keys, ticket validity durations, expiration dates, etc..
        *   **Authentication Server (AS)**: Authenticates the user and issues a **Ticket Granting Ticket (TGT)**. If you possess a valid TGT, it means the authentication server has verified your credentials.
        *   **Ticket Granting Server (TGS)**: The **application server** of the KDC. It provides a **service ticket**. You need to get a service ticket from the TGS before accessing any service on a Hadoop cluster.

### 5. Kerberos Authentication Flow in Hadoop (Example: Listing HDFS Directory)

Let's assume you want to list a directory from HDFS on a Kerberos-enabled Hadoop cluster:

1.  **User Authentication (using `kinit`)**:
    *   First, you must be authenticated by Kerberos on your Linux machine.
    *   You execute the `kinit` tool.
    *   The `kinit` program will ask you for your password.
    *   It sends an authentication request to the Kerberos Authentication Server (AS).
    *   On successful authentication, the AS responds with a **TGT (Ticket Granting Ticket)**.
    *   The `kinit` tool stores this TGT in your **credentials cache**. Now you have your TGT, signifying you are authenticated and ready to execute a Hadoop command.

2.  **Obtaining a Service Ticket (for NameNode)**:
    *   You run a Hadoop command, e.g., to list an HDFS directory, using a Hadoop client.
    *   The Hadoop client uses your TGT to reach out to the **TGS (Ticket Granting Server)**.
    *   The client requests a **service ticket for the NameNode service**.
    *   The TGS grants you a service ticket, and the client caches it. Now you have a ticket to communicate with the NameNode.

3.  **Communicating with NameNode (Mutual Authentication)**:
    *   The Hadoop RPC (Remote Procedure Call) mechanism uses this service ticket to communicate with the NameNode.
    *   They (client and NameNode) exchange tickets.
    *   Your ticket proves your identity to the NameNode, and the NameNode's ticket determines its identity to you. This process is called **mutual authentication** because both parties are sure they are talking to an authenticated entity.

4.  **Authorization**:
    *   After mutual authentication, if you have the necessary permissions to list the directory, the NameNode will return the results. (Note: HDFS authorization and file permissions are separate concepts from authentication, covered in other videos).